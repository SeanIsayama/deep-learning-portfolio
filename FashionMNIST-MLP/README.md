# 🧠 Multi-Layer Neural Network for FashionMNIST Classification

**CSE 151B – Deep Learning**  
**Winter 2025 @ UC San Diego**  
**Programming Assignment 1**

- 📄 [View Report (PDF)](./report.pdf)  
- 🔒 Code available upon request (private repository, per course policy)

---

## 📌 Overview

In this project, we implemented a multi-layer neural network (MLP) from scratch in NumPy to classify images from the FashionMNIST dataset. This involved:

- Forward and backward propagation
- Gradient checking
- Softmax loss, cross-entropy
- Momentum and regularization
- Activation functions (ReLU, tanh, sigmoid)
- Early stopping and performance visualization

---

## 👨‍👩‍👧‍👦 Team Members

- **Hikaru Isayama**
- **Avi Mehta**

---

## 🛠 My Contributions (Hikaru Isayama)

- Implemented numerical gradient checking to validate backpropagation
- Tuned models with momentum and L2 regularization
- Designed early stopping pipeline and tracked convergence behavior
- Contributed to LaTeX report write-up and training curve plots

---

## ✅ Results

Our best model achieved **88% test accuracy** using tanh activation, momentum, and L2 regularization. Key learnings include the sensitivity of optimization to activation choices and the importance of careful initialization and early stopping.

---

## ⚠️ Academic Policy

This project was completed for academic credit. Code is not public to preserve course integrity but is available upon request for recruiting purposes.